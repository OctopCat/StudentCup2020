# StudentCup2020 2nd(?) Place solution
## はじめに
- https://signate.jp/competitions/281 の解法です
- 開催者、参加者及び関係者各位に感謝します

## 注意書き
- NLPはTwitterコンペで遊んでいたくらいで、自分でまともにモデルを組んだのは初めてでした
- 誤ったことを言っている可能性があります
  - 遠慮なく刺してください
  - フォーラムでも自分で掘った穴に何回か落ちました
- test weightを使ったので、解法から除外される可能性があります
  - test weightで予測値を尤度最大化する（hack(prob)とかLBハックとかTLで言われているもの）くらいは大丈夫とのツイートを見ましたが、test weightを推定してフォーラムで公開した大本は自分なので…

## 気を付けた点

- クラス間不均衡
- TrainとTestの分布が異なる
- 指標がマクロF1

- 以上の点により、シェイクしそうだと思いました
  - 実際、割とシェイクしました
  - LBの順位表が0.01刻みくらいだったのと合わせて、順位は変動が大きかったようです
- シェイクを避けるために、同じくらいの重みでモデルの多様性を増やそうと考えました
- 基本的な方針は以下の通りです
  - GBDTも使う
  - NLPは色々変える
    - 再翻訳のAugment（1日前に思い出して追加）
  - Ensembleで重みが小さいモデルは外す



## モデル

- LightGBM + CatBoost + RoBERTA * 6 のEnsemble
- モデルはそれぞれStratifiedKFold (n=4)で学習・推論
- test weight / train weightで重みづけしたCross Entropy Lossを使い学習し、同様の重みのF1で評価
  - ここのtest weightにLBから推定した値を使用
  - 評価はF1ではなくAUCを試したかったが後回しにしていたら実装できず



### LightGBM (weight=0.14)

- ディスカッションのチュートリアルの前処理＋公開していたベースラインを少し変えたモデル
  - 変更点はKfold→StratifiedKFold, weightを加えたのみ
  - 適当に設定していた特徴量作成の閾値を弄ったらCVが下がったので放置



### CatBoost (weight=0.21)

- テキストにある不自然な空白（Tab Space?）の除去＋テキストをそのままつっこむ
  - CatBoostはテキストをそのまま特徴量として扱える
  - 下手に特徴量作成するとLightGBMと結果が似てしまい、Ensembleの時に微妙な結果になる



### RoBERTa

- NLPに詳しい人から見れば頓珍漢なことやっていると思います
- BERT, RoBERTa, XLNET, XLM, ALBERTなど試して、RoBERTaが一番良さそうだったので選択
  - 途中までは色々混ぜていたが、モデルの重みの大きさを考え、一番性能が良かったRoBERTaのみに絞った
  - 下の取ってくる部分を変えたモデルでも、大体RoBERTaが良かったので、RoBERTaに統一した
- 機械翻訳には癖があることが多いので、翻訳したデータと元データは別個（別々のモデル）で学習させた
  - 効いたかは不明
  - 最近は翻訳の質が高くなっているので不要だったかもしれない
- Sequential毎の設定（Optimizerなど）は適宜試し、一番単純な全層同じパラメータのAdamで学習しました



- head (weight=0.11)
  - 普通の分類用ヘッドをとる [:, 0, :]
- mean (weight=0.09)
  - 特徴量の平均を取る torch.mean(output, dim=1)
- tail (weight=0.20)
  - 文末の特徴量を取る [:, -1, :]
  - 文末にツールの名詞が乗っている場合が多かったので、文末から特徴量を取れると考えた
- concat(head, tail) (weight=0.02)
  - 通常、分類問題に文末から特徴量は取らないので、headで多少緩和しようと考えた
  - （入れない方が良かったかもしれない）
- French(tail) (weight=0.15)
  - 英語→フランス語→英語に変換して学習
  - 文末の特徴量を取る
    - 時間が無く、文末が本当に良かったかは不明
- Deutsch(tail) (weight=0.09)
  - 英語→ドイツ語→英語に変換して学習
  - 文末の特徴量を取る
    - 時間が無く、文末が本当に良かったかは不明



### Ensemble & Post Processing

- モデルごとの重み、クラスごとの重みを乱数で発生させて、総和が1になるようにそれぞれ正規化
- 重みに従い予測して、スコアが良ければ重みを更新
  - 5万回か10万回くらい実行時間を見て回す
  - 回し終わった後、重みが小さいモデルがあれば削除してもう一度回す
- Fold切ってないので多少Leakしていると思うが、LB見て手動で重み付けるより楽
- その後、ディスカッション上のhack(prob)を使用
  - Privateスコアを見る限りPseudo Labelingでも似たことができたようだが、こちらの方が安定して精度が良かった
  - ここでもtest weightを使用
    - 終了1時間前くらいにディスカッションで使用したらまずい的な投稿があったようだが、翌日インターンあるので普通に寝ていた
    - 学習段階でもTest weight使っているので、起きてたところで打つ手はなかった
    - 終了2週間以上前にtest weightはディスカッションで判明して（公開して）、hack(prob)も10日前くらいには出ていて運営が何も言ってなかったので、何も考えていなかった



## 感想など

- 以下は個人的な感想です

- 去年もディスカッションでベースラインを投稿していましたが、投稿後もディスカッションが冷えていたことを反省していました
  - LBを気にして弱いベースラインしか出さなかった結果、ベースラインにもなりませんでした
- 今年は敷居が高いNLPだったこともあり、NLPを使わないベースラインとNLPを使ったベースラインの双方を、投稿時のLBで上位20%くらいでしたが投げました
  - 結果的に温まったので良かったと思います

- PublicとPrivateがほぼ同じ分布だったのでこのような結果になりましたが、もし違っていたらMicrosoft（今回の協賛企業の一つ）の某コンペのようになっていたかもしれないと思いました

